import numpy as np

"""
Based on C4.5 - the classifier (it is not for regression)
X contains the attributes that the algorithm can learn from per example
Y are the target values per example
"""
class Decision_Tree:
	def __init__(self, X=np.zeros((0,0)), Y=np.zeros(0)):
		assert type(X) is np.ndarray , "attribute values X is not ndarray"
		assert len(X.shape)==2, "attribute values X has more that two dimensions"
		assert X.shape[0]>0, "attribute values X has no examples"
		assert X.shape[1]>0, "attribute values X has no attributes"
		
		assert type(Y) is np.ndarray , "target values Y is not ndarray"
		assert len(Y.shape)==1, "target values Y has more that two dimensions"
		assert Y.shape[0]==X.shape[0], "target values Y has no examples"
		
		self.n_exp  = X.shape[0]	# nr of examples
		self.n_attr = X.shape[1]-1	# nr of attributes
		
		self.root = Decision_Node(X, Y)


	def classify(self, example):
		return self.root.classify(example)



class Decision_Node:
	def __init__(self, X, Y):
		self.value = None
		if np.allclose(Y, Y[0]): #check if this is a leaf which is "pure"
			self.value = Y[0]
			return
		self.attribute, self.separation_value, self.information_gain = self.select_attribute_at_random(X, Y)
		# TODO check for leaf again - for example inseparable examples
		left_idx  = X[:,self.attribute] <= self.separation_value
		right_idx = X[:,self.attribute] >  self.separation_value
		left_X, left_Y   = X[left_idx],  Y[left_idx]
		right_X, right_Y = X[right_idx], Y[right_idx]
		self.lc = Decision_Node(left_X,  left_Y)
		self.rc = Decision_Node(right_X, right_Y)
	
	def select_attribute_at_random(self, X, Y):
		nr_examples, nr_attributes = X.shape[0], X.shape[1]
		attribute_information_gains = np.zeros(nr_attributes)
		attribute_values = np.zeros(nr_attributes)
		for attr_idx in range(nr_attributes):
			tmp = np.sort(X[:,attr_idx])
			# either trends towards mean of median...
			attr_val = (tmp[-1]-tmp[0]) * np.random.rand() + tmp[0]
			#print "attribute value: ", tmp[0], attr_val, tmp[-1]
			#if np.random.rand()<0.5: attr_val = tmp[np.random.randint(0,nr_examples)]
			attribute_information_gains[attr_idx] = self.information_gain(X,Y, attr_idx, attr_val)
			attribute_values[attr_idx] = attr_val
		best_attr_idx  = np.argmax(attribute_information_gains)
		best_attr_val  = attribute_values[best_attr_idx]
		best_info_gain = attribute_information_gains[best_attr_idx]
		return best_attr_idx, best_attr_val, best_info_gain

	def information_gain(self, X, Y, attribute_idx, attribute_value):
		idx_smaller = X[:, attribute_idx] <= attribute_value
		idx_larger  = X[:, attribute_idx] >  attribute_value
		return self.entropy(Y) - (self.entropy(Y[idx_smaller])+self.entropy(Y[idx_larger]))

	def entropy(self, Y):
		"""
		Returns the entropy as defined in information theory
		"""
		entropy = 0
		for val in list(set(Y)):
			p = (Y==val).sum()*1.0 / len(Y)
			entropy -= p*np.log2(p)
		return entropy

	def classify(self,example):
		if self.value != None: return self.value
		if example[self.attribute] <= self.separation_value:
			return self.lc.classify(example)
		return self.rc.classify(example)
		



if __name__=="__main__":

	"""
	creates a tree with 100 classes and one example per class
	this leads to 100 leaves
	when classifying an arange in the bottom, arange(cols) + q*cols
		leads to class q
	"""
	rows = 20
	cols = 5
	classes = 4
	X = np.arange(rows*cols).reshape(rows,cols)
	#X[:,-1] = X[:,-1] % classes
	Y = np.arange(rows)
	#Y = Y%classes
	print X
	print Y
	a = Decision_Tree(X,Y)

	print "class is: ", a.classify(np.arange(cols)+4*cols)








